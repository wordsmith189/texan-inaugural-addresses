---
title: "3 Keywords"
description: |
  Which keywords are frequent, and which are significant?
author:
  - name: Lars Hinrichs
    url: https://larshinrichs.site
    affiliation: The University of Texas at Austin
date: 12-24-2020
draft: false
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      cache = F)
library(pacman)
p_load(tidyverse, tidytext, tm, quanteda,
       knitr, kableExtra, rio, extrafont,
       cowplot)
```

```{r show-img}
include_graphics("key.png")
```

```{r load-data}
corpus <- import("../../data/corpus.RDS")
```

## Most frequent words

For the first analysis we'll remove stopwords (see a [definition of stopwords here](https://en.wikipedia.org/wiki/Stop_word)). And then we will count the occurrences of each distinct word and see what's most frequent!

```{r make-plots}
pal <- wesanderson::wes_palette("GrandBudapest1", 4)

inaugurals_words <- 
  corpus %>% 
  unnest_tokens(word, text) %>% 
  mutate(word = recode(word,
                       `america's` = "america",
                       american = "america",
                       americans = "america")) %>% 
  count(doc_id, word, sort = T)

inaugurals_total_n <- 
  inaugurals_words %>% 
  group_by(doc_id) %>% 
  summarize(total = sum(n))

inaugurals_words <- 
  inaugurals_words %>% 
  left_join(inaugurals_total_n)

inaugurals_toplot <- inaugurals_words %>%
  #bind_tf_idf(word, author, n) %>%
  filter(!word %in% stop_words$word) %>% 
  mutate(
    freq = n/total,
    nwords = n
    )

docs <- inaugurals_toplot %>% 
  pull(doc_id) %>% 
  as.character() %>% 
  unique()

pfunct <- 
  function(dat, i){ 
  dat %>%
    filter(doc_id == 
           docs[i]) %>% 
    head(15) %>% 
    #mutate(word = reorder(word, freq)) %>%
    ggplot(aes(x = reorder(word, nwords), 
               y = nwords)) +
    geom_col(show.legend = FALSE,
             width = 0.45,
             fill = pal[i]) +
    coord_flip() +
    labs(x = "", y = "frequency in text",
         title = docs[i]) +
    theme_classic(base_family = "Volkhov-Regular",
                  base_size = 12)
}

```

```{r printplots1-4, layout="l-outset", fig.height=8, fig.cap="Top 15 terms in each Texan inaugural address by raw frequency."}
p1 <- pfunct(inaugurals_toplot, 3)
p2 <- pfunct(inaugurals_toplot, 4)
p3 <- pfunct(inaugurals_toplot, 2)
p4 <- pfunct(inaugurals_toplot, 1)
plot_grid(p1, p2, p3, p4, ncol=2)
```

## Most important words by tf-idf

An advanced measure of the importance of words in documents is `tf-idf`. It is calculated using a formula that takes into account both each word's raw frequency as well as the number of documents in the corpus in which it is used. This method is a way of finding out **the most distinctive words in each text**.

<aside>`tf-idf` is defined in detail [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).</aside>

For example, in the context at hand, you might expect that each of the four speeches contains the words *freedom* or *people*. And while it is certainly interesting which president used them the most, these words aren't really distinctive, simply because each president uses them on this occasion. But it's instructive to look at the words that are *both frequent and unique* to each speech.

```{r}
inaugurals_tf_idf <- 
  inaugurals_words %>%
  bind_tf_idf(word, doc_id, n) %>% 
  select(-total) %>%
  anti_join(stop_words) %>% 
  arrange(desc(tf_idf))
```

```{r tf-idf}
pfunct2 <- 
  function(dat, i){ 
  dat %>%
    filter(doc_id == 
           docs[i]) %>% 
    head(15) %>% 
    ggplot(aes(x = reorder(word, tf_idf), 
               y = tf_idf)) +
    geom_col(show.legend = FALSE,
             width = 0.45,
             fill = pal[i]) +
    coord_flip() +
    labs(x = "", y = "tf_idf",
         title = docs[i]) +
    theme_classic(base_family = "Volkhov-Regular",
                  base_size = 12)
}
```

```{r printplots5-8, layout="l-outset", fig.height=8, fig.cap="Top 15 terms in each Texan inaugural address by tf-idf."}
p5 <- pfunct2(inaugurals_tf_idf, 3)
p6 <- pfunct2(inaugurals_tf_idf, 4)
p7 <- pfunct2(inaugurals_tf_idf, 2)
p8 <- pfunct2(inaugurals_tf_idf, 1)
plot_grid(p5, p6, p7, p8, ncol=2)
```
