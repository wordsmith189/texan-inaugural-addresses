[
  {
    "path": "posts/1-the-data/",
    "title": "1 The Data",
    "description": "Scope, source, and preparation of the data.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-12-25",
    "categories": [],
    "contents": "\n\nContents\nScope of the data\nSource of the data\n\nScope of the data\nWe analyze the inaugural addresses of the “Texan” presidents. These are\nLindon B. Johnson (1)\nGeorge H.W. Bush (1)\nGeorge W. Bush (2)\nTo justify this choice, it is important to note that we are interested in “culturally” Texan presidents. If we were interested in place of birth, we’d also have to include Eisenhower (born in TX but didn’t live there), and not the Bushes (born outside of TX but lived there).\n\n\n\nSource of the data\nWe’re using the version of the speeches that is included in the quanteda R-package (Benoit et al. 2018). The following code grabs the speeches from the package in the corpus data format, then converts it to a regular dataframe.\n\n\ntxpres <- c(\"Johnson\", \"Bush\")\ncorpus <- data_corpus_inaugural %>% \n  quanteda::convert(to = \"data.frame\") %>% \n  filter(President %in% txpres) %>% \n  mutate(nickname = case_when(\n    FirstName == \"Lyndon Baines\" ~ \"LBJ\",\n    FirstName == \"George\" ~ \"Bush41\",\n    TRUE ~ \"Bush43\"\n  )) %>% \n  janitor::clean_names()\n\ncorpus %>% \n  mutate(text = str_sub(text, 1, 40)) %>% \n  as_tibble() %>% \n  kbl() %>% \n  kable_paper()\n\n\n\ndoc_id\n\n\ntext\n\n\nyear\n\n\npresident\n\n\nfirst_name\n\n\nparty\n\n\nnickname\n\n\n1965-Johnson\n\n\nMy fellow countrymen, on this occasion,\n\n\n1965\n\n\nJohnson\n\n\nLyndon Baines\n\n\nDemocratic\n\n\nLBJ\n\n\n1989-Bush\n\n\nMr. Chief Justice, Mr. President, Vice P\n\n\n1989\n\n\nBush\n\n\nGeorge\n\n\nRepublican\n\n\nBush41\n\n\n2001-Bush\n\n\nPresident Clinton, distinguished guests\n\n\n2001\n\n\nBush\n\n\nGeorge W.\n\n\nRepublican\n\n\nBush43\n\n\n2005-Bush\n\n\nVice President Cheney, Mr. Chief Justice\n\n\n2005\n\n\nBush\n\n\nGeorge W.\n\n\nRepublican\n\n\nBush43\n\n\nDown the line, this data can be tokenized and/or marked up as needed. We’ll save this version so we can come back to it.\n\n\n\n\n\n\nBenoit, Kenneth, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng, Stefan Müller, and Akitaka Matsuo. 2018. “Quanteda: An r Package for the Quantitative Analysis of Textual Data.” Journal of Open Source Software 3 (30): 774. https://doi.org/10.21105/joss.00774.\n\n\n\n\n",
    "preview": "posts/1-the-data/lbj.inaug.jpg",
    "last_modified": "2020-12-30T19:38:37-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2-numeric-measures/",
    "title": "2 Numeric Measures",
    "description": "Sentence lengths, number of words, etc.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-12-25",
    "categories": [],
    "contents": "\n\nContents\nWords\nSentences\nNumber of words per sentence\n\n\n\n\n\n\n\nWords\nHere is the overall length of each address.\n\n\n\nSentences\nNumber of sentences in each address.\n\n\n\nNumber of words per sentence\nWho used the longest sentences?\n\n\n\n\n\n\n",
    "preview": "posts/2-numeric-measures/measure.jpg",
    "last_modified": "2020-12-31T06:17:43-05:00",
    "input_file": "2-numeric-measures.utf8.md"
  },
  {
    "path": "posts/3-keywords/",
    "title": "3 Keywords",
    "description": "Which terms are frequent, and which are significant?",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-12-24",
    "categories": [],
    "contents": "\n\n\n\n\n\n\nMost frequent words\nFor the first analysis we’ll remove stopwords (see a definition of stopwords here). And then we will count the occurrences of each distinct word and see what’s most frequent!\n\n\n\n\n\n\nFigure 1: Top 15 terms in each Texan inaugural address by frequency.\n\n\n\nMost important words by tf-idf\nAn advanced measure of the importance of words in documents is tf-idf. It is calculated using a formula that takes into account both each word’s raw frequency as well as the number of documents in the corpus in which it is used. This method is a way of finding out the most distinctive words in each text.\ntf-idf is defined in detail here.\nFor example, in the context at hand, you might expect that each of the four speeches contains the words freedom or people. And while it is certainly interesting which president used them the most, these words aren’t really distinctive, simply because each president uses them on this occasion. But it’s instructive to look at the words that are both frequent and unique to each speech.\n\n\n\n\n\n\n\n\n\nFigure 2: Top 15 terms in each Texan inaugural address by tf-idf.\n\n\n\n\n\n\n",
    "preview": "posts/3-keywords/key.png",
    "last_modified": "2021-01-04T08:26:08-05:00",
    "input_file": "3-keywords.utf8.md",
    "preview_width": 606,
    "preview_height": 185
  }
]
